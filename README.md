
<p align="center">

![Image Alt text](/readme_images/inicial.png)

</p>

<p align="center">
<img src="https://img.shields.io/badge/docker-24.0.7-blue"/>
<img src="https://img.shields.io/badge/docker--compose-2.23.3-9cf"/>
<img src="https://img.shields.io/badge/python-3.11-yellowgreen"/>
<img src="https://img.shields.io/badge/framework-fastAPI-brightgreen"/>
<img src="https://img.shields.io/badge/mongo-7.0.5-green"/>
<img src="https://img.shields.io/badge/postgres-16.1-lightgrey"/>
<img src="https://img.shields.io/badge/redis-6.2.5--alpine-red"/>
<img src="https://img.shields.io/badge/rabbitmq-3.10.2--alpine-orange"/>
</p>

---

<h1 align="center">
   üöÄ Processamento ass√≠ncrono
</h1>
<p align="center">
    <em>
    Projeto desenvolvido com o intuito de exercitar o processamento ass√≠ncrono em conjunto com um sistema de tentativas, tratamento de falhas, triggers e logs 
    </em>
</p>

---

Sum√°rio
=================

   * [O projeto](#o-projeto)
   * [Bancos de Dados DB1 e DB2](#bancos-de-dados-db1-e-db2)
   * [APIs Sistema 1 e Sistema 2](#apis-sistema-1-e-sistema-2)
   * [Orquestrador de processos](#orquestrador-de-processos)
   * [Filas](#filas)
   * [Consumidor](#consumidor)
   * [Logs de execu√ß√£o](#logs-de-execu√ß√£o)
        * [Estrutura](#estrutura)
        * [Visualiza√ß√£o](#visualiza√ß√£o)
   * [Banco de dados para endput](#banco-de-dados-para-endput)
        * [Detalhe](#detalhe)
        * [Resultado esperado](#resultado-esperado)
   * [Makefile](#makefile)

   

---

## O projeto

Este projeto √© uma prova de conceito para explorar e exercitar diversas funcionalidades pautadas em diversas tecnologias e suas integra√ß√µes. O projeto √© composto por:

1. Um banco de dados Redis. Focado em orquestrar os processos que ser√£o rodados nas APIs.
2. API 1 utilizando fastAPI. Essa API ter√° um endpoint para preencher o DB conectado √† ela e alguns endpoints envolvendo o processo de gerar mensagens e enviar mensagens para nossa fila prim√°ria.
3. Banco de dados PostgreSQL. Respons√°vel por guardar informa√ß√µes basica de um pedido, possivelmente um pedido de uma loja ou marketplace.
4. API 2 utilizando fastAPI. Esta API √© uma c√≥pia da anterior. Contudo, foi inserida para demonstrar processamento paralelo e inser√ß√£o dupla numa mesma exchange/fila.
5. Banco de dados PostgreSQL. Semelhante ao ponto 3, contudo relacionado √† API 2.
6. Fila prim√°ria utilizando RabbitMQ. Est√° configurada com um plugin de delay de mensagens de 10 segundos (configur√°vel) para voltar para a fila.
7. Fila DLQ  utilizando RabbitMQ. √â trigada pela falha de processamento da filha prim√°ria ap√≥s processar sem sucesso durante 5x.
8. Consumidor em Python. √â acionado a partir da fila prim√°ria. Tem a fun√ß√£o de logar tudo que roda nele no mongo e exercer a fun√ß√£o de guardar as informa√ß√µes recebidas da mensagem no PostgreSQL.
9. Um banco de dados mongoDB. Respons√°vel por servir de log para tudo que √© consumido no consumer. Nesse banco h√° um TTL configur√°vel.
10. Banco de dados PostgreSQL. Relacionado √† guardar todas as informa√ß√µes processadas pelo consumidor, ou seja, que passaram pela fila e foram processadas com sucesso.

---

## Bancos de Dados DB1 e DB2

Esses bancos de dados possuem uma estrutura simples. Apenas um schema e uma tabela. Contudo, estes foram escolhidos para simbolizar que poder√≠amos inserir um banco com estrutura mais complexa e ainda assim funcionaria na solu√ß√£o adotada.

Tanto os bancos DB1 e DB2 possuem estruturas iguais. Segue algumas particularidades:

1. O campo ID √© sequencial, mas esse dado n√£o ser√° importante na nossa prova de conceito. Optei por n√£o realizar nenhuma associa√ß√£o dele ao meu resultado gerado no banco DB Endput.
2. O campo created_at tamb√©m n√£o ser√° reaproveitado no nosso output.
3. Os campos que ser√£o reaproveitados no nosso endput ser√£o "product", "price" e "security_check".
4. O campo "security_check" n√£o est√° realizando nenhuma verifica√ß√£o de seguran√ßa. Este, foi criado como um booleano para servir de base para a l√≥gica que ser√° apresentada nas filas e para podermos visualizar na tabela de endput o resultado de maneira mais clara.
5. H√° um endpoint em cada uma das APIs para auxiliar no preenchimento dos dados desses 2 bancos.

![Image Alt text](/readme_images/postgresql.png)

_DB1_: http://localhost:5432

_DB2_: http://localhost:5433

---

## APIs Sistema 1 e Sistema 2

Estas APIs s√£o iguais e foram criadas com o aux√≠lio do framework fastAPI. Estas possuem apenas 4 endpoints que podem ser acessadas atrav√©s de suas respectivas documenta√ß√µes que podem ser encontradas em "/docs" e "/redoc".

Para testarmos os "retrys" da fila, criamos uma l√≥gica dentro das APIs das quais o cosumidor futuramente se beneficiar√°. Segue a logica de envio de mensagens para a fila:

1. Em cada linha do banco lida, o sistema verifica o campo "security_check".
2. CASO esse campo esteja pr√© preenchido como TRUE, a API anexa √† mensagem um numero m√°ximo de processamento que varia de 1 a 5x. ( Dado que o numero m√°ximo aceito pelo consumidor em termos de processamento de uma mesma mensagem √© 5 )
3. CASO esse campo esteja pr√© preenchido como FALSE, a API anexa √† mensagem um n√∫mero m√°ximo de processamento de 6x. Sabendo que esse numero extrapola o m√°ximo de tentativas, saberemos que essa mensagem ir√° falhar.
4. Na pr√°tica, as mensagem com "security_check" = FALSE sempre ir√£o falhar no processamento do consumidor e nunca chegar√£o ao nosso banco de dados destino.
5. Outra maneira de encontrar as linhas "security_check" = FALSE √© verificar ao termino do processamento se elas se encontram na DLQ.

![Image Alt text](/readme_images/fastapi.png)

_API1_: http://localhost:8001/docs

_API2_: http://localhost:8002/docs

---

## Orquestrador de processos

Com o intuito de criar uma funcionalidade para permitir que nossas APIs processem somente linhas do banco que n√£o foram previamente processadas, utilizamos o Redis para orquestrar esses processos.

A estrutura do Redis √© bem enxuta, teremos pouca informa√ß√£o contida nela. A fun√ß√£o principal dessa estrutura √© registrar qual a √∫ltima linha do banco que foi processada. Assim, na pr√≥xima vez que precisarmso processar algo, partiremos da ultima linha processada + 1.

![Image Alt text](/readme_images/orquestrador.png)

_Redis_: http://localhost:6379

---

## Filas

As filas desse projeto est√£o utilizando RabbitMQ e um plugin de delay de entrada √† fila. As mensagens processadas pelas APIs, caem na fila principal (tamb√©m chamada de "primary"). 

Atrav√©s do "localhost:15672" ser√° poss√≠vel analisar as filas, exchanges e demais componentes do RabbitMQ que foram cadastrados automaticamente pelas configura√ß√µes contidas no c√≥digo.

Funcionamento de seu processamento:
1. Caso essas mensagens sejam processadas com sucesso, elas saem da fila prim√°ria.
2. Caso sejam processadas sem sucesso, MAS, ainda n√£o estourou o limite de at√© 5 processamentos, a mensagem volta √† fila. Como h√° um plugin de delay de volta √† fila, a mensagem pode demorar um tempo customiz√°vel para voltar.
3. Caso a mensagem ultrapasse o limite m√°ximo de processamentos sem sucesso, a mensagem ir√° cair na "fila morta", tamb√©m chamada de DLQ. 

![Image Alt text](/readme_images/rabbitMQ.png)

_RabbitMQ_: http://localhost:15672

---

## Consumidor

O consumidor ser√° um agente bastante demandado da estrutura apresentada. Este ficar√° ouvindo a fila, registrando seu processamento em um banco de dados e registrando informa√ß√µes em outro banco de dados quando conseguir realizar um processamento com sucesso.

![Image Alt text](/readme_images/consumidor.png)

---

## Logs de execu√ß√£o

Os logs de execu√ß√£o ser√£o escritos no mongoDB. Esse banco foi configurado para aceitar uma quantidade de segundos equivalente √† um TTL. Ou seja, seus dados ir√£o se autodestruir ap√≥s um tempo configur√°vel de sua escrita no banco.

### Estrutura

A estrutura do log engloba algumas coisas:

1. Identificador para a mensagem.
    1. O _id √© gerado automaticamente para cada mensagem que entra na fila. Caso uma mensagem seja processada erroneamente, ela voltar√° para a fila, por√©m com um _id diferente. Para solucionar isso, temos o campo "message_id".
    2. O campo "message_id" √© bastante √∫til pra gente, pois, ao pesquisar sobre uma determinada mensagem, conseguimos obter o historico de processamento dela, seus status e suas informa√ß√µes.
2. Area de processamento. Nessa area guardamos dados referentes √†:
    1. Em qual tentativa estamos?
    2. Status atual do processamento.
    3. Quantidade de tentativas necess√°rias para que a mensagem seja lida com sucesso. (Caso esse campo possua o valor "6", sabemos que esta nunca ser√° lida com sucesso)
3. Informa√ß√µes de origem da mensagem.
4. Dados referentes ao processamento da mensagem em si.
5. Campo de data do processamento. Esse campo ser√° utilizado como refer√™ncia para o mongodb saber quando auto excluir algumas de suas linhas baseado no tempo de cria√ß√£o.

![Image Alt text](/readme_images/mongodb.png)

### Visualiza√ß√£o

H√° uma ferramenta visual para enxergarmos o conte√∫do desse banco de dados. A ferramenta "Mongo Express" est√° dispon√≠vel para verifica√ß√£o.

Ao selecionar o database "local" e collection "messagem", podemos encontrar nossos logs. Nessa p√°gina podemos tamb√©m pegar um "message_id" e pesquisar na area de busca para descobrir o hist√≥rico de processamento de uma mensagem.

![Image Alt text](/readme_images/mongodb2.png)

_Mongo Express_: http://localhost:8081

---

## Banco de dados para endput

Ap√≥s o processamento bem sucedido de todas as mensagens, a ideia do projeto √© gravar numa tabela dentro de um outro banco postgresql todas as "orders" que possuam o "security_check" = TRUE.

### Detalhe

Nos detalhes desse banco, podemos perceber sua simplicidade, seguindo o padr√£o de um schema e uma tabela. A escolha desse banco se fez para seguir um padr√£o com os bancos de entrada e mostrar que em casos reais e complexos, seria uma poss√≠vel op√ß√£o.

![Image Alt text](/readme_images/endput.png)

### Resultado esperado

Dentro do resultado buscado nesse campo, veremos apenas campos com o security_check abaixo. Teremos tamb√©m a quantidade de linhas esperada para os inputs de securities positivos dentros das APIs.

![Image Alt text](/readme_images/endput2.png)

_DB Endput_: http://localhost:5434

---

## Makefile

Com o intuito de facilitar e agilizar a subida, descida e limpeza dos containers, um Makefile foi criado. Os comandos "make start_with_logs" e "make stop" s√£o provavelmente os comandos mais importantes para auxiliar na hora de iniciar e parar esse projeto.

---